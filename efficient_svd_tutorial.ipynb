{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:34:11.239160Z",
     "start_time": "2025-04-13T17:34:09.233816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/ToelUl/EfficientSVD.git\n",
    "\n",
    "!cp -r EfficientSVD/universal_svd ./"
   ],
   "id": "c4b643535b632f97",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Experiencing EfficientSVD in Google Colab\n",
    "\n",
    "This notebook provides a hands-on demonstration of the `EfficientSVD` class. `EfficientSVD` is a Python module designed to compute Singular Value Decomposition (SVD) efficiently by leveraging optimal backends (PyTorch, SciPy, Scikit-learn) based on the input matrix type, size, and desired computation method.\n",
    "\n",
    "**Goals:**\n",
    "* Install necessary libraries.\n",
    "* Define the `EfficientSVD` class.\n",
    "* Demonstrate various SVD computation methods:\n",
    "    * `auto`: Automatic backend selection.\n",
    "    * `full`: Computes the complete SVD.\n",
    "    * `truncated`: Computes the top `k` singular values/vectors (using SciPy or Scikit-learn).\n",
    "    * `randomized`: Computes an approximate truncated SVD using randomized algorithms (Scikit-learn).\n",
    "    * `values_only`: Computes only the singular values efficiently (using PyTorch if available).\n",
    "* Show usage with different input types:\n",
    "    * NumPy arrays\n",
    "    * SciPy sparse matrices\n",
    "    * PyTorch tensors (including GPU acceleration if available)\n",
    "\n",
    "**Running the Notebook:**\n",
    "* Execute the cells sequentially using Shift+Enter or the \"Run\" button.\n",
    "* Ensure the runtime type is set appropriately (CPU, GPU, or TPU) via `Runtime > Change runtime type`. GPU is recommended if you want to test PyTorch GPU acceleration in Example 6."
   ],
   "id": "236081b9691a5796"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:45:38.198497Z",
     "start_time": "2025-04-13T17:45:36.642192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Setup: Install Libraries\n",
    "# Install necessary libraries. PyTorch, SciPy, and Scikit-learn provide different SVD backends.\n",
    "# Use -q for quieter installation in Colab.\n",
    "print(\"Installing required libraries...\")\n",
    "!pip install -q numpy scipy scikit-learn torch\n",
    "print(\"Installation complete.\")\n",
    "\n",
    "# Import base libraries required immediately\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Check available libraries after installation\n",
    "try:\n",
    "    import torch\n",
    "    _TORCH_AVAILABLE = True\n",
    "    print(f\"PyTorch version: {torch.__version__} (Available: {_TORCH_AVAILABLE})\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"GPU not available or PyTorch CUDA build not installed.\")\n",
    "except ImportError:\n",
    "    _TORCH_AVAILABLE = False\n",
    "    print(\"PyTorch not found.\")\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "    from scipy.sparse import spmatrix as scipy_sparse_matrix\n",
    "    from scipy.sparse.linalg import svds as scipy_svds\n",
    "    from scipy.sparse import random as sparse_random\n",
    "    _SCIPY_AVAILABLE = True\n",
    "    print(f\"SciPy version: {scipy.__version__} (Available: {_SCIPY_AVAILABLE})\")\n",
    "except ImportError:\n",
    "    scipy_sparse_matrix = None\n",
    "    scipy_svds = None\n",
    "    sparse_random = None\n",
    "    _SCIPY_AVAILABLE = False\n",
    "    print(\"SciPy not found.\")\n",
    "\n",
    "try:\n",
    "    import sklearn\n",
    "    from sklearn.decomposition import TruncatedSVD as SklearnTruncatedSVD\n",
    "    from sklearn.utils.extmath import randomized_svd as sklearn_randomized_svd\n",
    "    from sklearn.utils.validation import check_random_state\n",
    "    _SKLEARN_AVAILABLE = True\n",
    "    print(f\"Scikit-learn version: {sklearn.__version__} (Available: {_SKLEARN_AVAILABLE})\")\n",
    "except ImportError:\n",
    "    SklearnTruncatedSVD = None\n",
    "    sklearn_randomized_svd = None\n",
    "    check_random_state = None\n",
    "    _SKLEARN_AVAILABLE = False\n",
    "    print(\"Scikit-learn not found.\")\n",
    "\n",
    "from universal_svd import EfficientSVD\n",
    "print(\"EfficientSVD class defined.\")"
   ],
   "id": "95725c91b9bb44bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required libraries...\n",
      "Installation complete.\n",
      "PyTorch version: 2.5.1+cu124 (Available: True)\n",
      "GPU available: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "SciPy version: 1.15.2 (Available: True)\n",
      "Scikit-learn version: 1.6.1 (Available: True)\n",
      "EfficientSVD class defined.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Demonstration Setup\n",
    "\n",
    "Let's create some test matrices:\n",
    "1.  A **dense NumPy array**.\n",
    "2.  A **sparse SciPy matrix** (if SciPy is available).\n",
    "3.  A **PyTorch tensor** (if PyTorch is available).\n",
    "\n",
    "We'll also define some common parameters for the SVD computations."
   ],
   "id": "89875c4e021e0a11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:48:16.406320Z",
     "start_time": "2025-04-13T17:48:16.381879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Prepare Example Data\n",
    "\n",
    "# --- Configuration ---\n",
    "M, N = 1000, 500       # Dimensions for larger matrices\n",
    "M_small, N_small = 100, 50 # Dimensions for full SVD example\n",
    "K_COMPONENTS = 20      # Number of components for truncated/randomized SVD\n",
    "SPARSITY = 0.05        # Sparsity level for the sparse matrix\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# --- Create Dense NumPy Matrix ---\n",
    "print(f\"\\nCreating a dense NumPy matrix (matrix_np) with shape ({M}x{N})\")\n",
    "matrix_np = np.random.rand(M, N).astype(np.float32)\n",
    "print(f\"matrix_np: type={type(matrix_np)}, shape={matrix_np.shape}, dtype={matrix_np.dtype}\")\n",
    "\n",
    "# --- Create Smaller Dense NumPy Matrix (for Full SVD) ---\n",
    "print(f\"\\nCreating a smaller dense NumPy matrix (matrix_np_small) with shape ({M_small}x{N_small})\")\n",
    "matrix_np_small = np.random.rand(M_small, N_small).astype(np.float32)\n",
    "print(f\"matrix_np_small: type={type(matrix_np_small)}, shape={matrix_np_small.shape}, dtype={matrix_np_small.dtype}\")\n",
    "\n",
    "\n",
    "# --- Create Sparse SciPy Matrix ---\n",
    "matrix_sparse = None\n",
    "if _SCIPY_AVAILABLE and sparse_random is not None:\n",
    "    print(f\"\\nCreating a sparse SciPy CSR matrix (matrix_sparse) with shape ({M}x{N}) and sparsity {SPARSITY}\")\n",
    "    matrix_sparse = sparse_random(M, N, density=SPARSITY, format='csr', random_state=RANDOM_SEED).astype(np.float32)\n",
    "    print(f\"matrix_sparse: type={type(matrix_sparse)}, shape={matrix_sparse.shape}, nnz={matrix_sparse.nnz}, dtype={matrix_sparse.dtype}\")\n",
    "else:\n",
    "    print(\"\\nSkipping sparse matrix creation: SciPy not available or `sparse_random` failed to import.\")\n",
    "\n",
    "# --- Create PyTorch Tensor ---\n",
    "matrix_torch = None\n",
    "if _TORCH_AVAILABLE:\n",
    "    print(f\"\\nCreating a PyTorch tensor (matrix_torch) with shape ({M}x{N}) from the NumPy matrix\")\n",
    "    matrix_torch = torch.from_numpy(matrix_np.copy()) # Use copy to avoid sharing memory if numpy array is modified later\n",
    "    print(f\"matrix_torch: type={type(matrix_torch)}, shape={matrix_torch.shape}, dtype={matrix_torch.dtype}, device={matrix_torch.device}\")\n",
    "    # Optional: Move to GPU if available\n",
    "    # if torch.cuda.is_available():\n",
    "    #     try:\n",
    "    #         matrix_torch = matrix_torch.cuda()\n",
    "    #         print(f\"Moved matrix_torch to GPU: {matrix_torch.device}\")\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Failed to move tensor to GPU: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping PyTorch tensor creation: PyTorch not available.\")\n",
    "\n",
    "# --- Instantiate the SVD Computer ---\n",
    "svd_computer = EfficientSVD(random_state=RANDOM_SEED) # Set default random state for reproducibility\n",
    "print(\"\\nEfficientSVD instance created.\")"
   ],
   "id": "6740b61301643595",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a dense NumPy matrix (matrix_np) with shape (1000x500)\n",
      "matrix_np: type=<class 'numpy.ndarray'>, shape=(1000, 500), dtype=float32\n",
      "\n",
      "Creating a smaller dense NumPy matrix (matrix_np_small) with shape (100x50)\n",
      "matrix_np_small: type=<class 'numpy.ndarray'>, shape=(100, 50), dtype=float32\n",
      "\n",
      "Creating a sparse SciPy CSR matrix (matrix_sparse) with shape (1000x500) and sparsity 0.05\n",
      "matrix_sparse: type=<class 'scipy.sparse._csr.csr_matrix'>, shape=(1000, 500), nnz=25000, dtype=float32\n",
      "\n",
      "Creating a PyTorch tensor (matrix_torch) with shape (1000x500) from the NumPy matrix\n",
      "matrix_torch: type=<class 'torch.Tensor'>, shape=torch.Size([1000, 500]), dtype=torch.float32, device=cpu\n",
      "\n",
      "EfficientSVD instance created.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 1: Auto Method\n",
    "\n",
    "Let `EfficientSVD` automatically choose the best backend for truncated SVD on the dense NumPy matrix. We expect it to likely use a randomized or truncated method since `k` is specified and relatively small compared to matrix dimensions."
   ],
   "id": "368d2ed6abf9c0ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:49:14.676742Z",
     "start_time": "2025-04-13T17:49:14.604719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Example 1: Auto SVD (k=K_COMPONENTS) on NumPy Array\n",
    "\n",
    "print(f\"\\n--- Example 1: Auto SVD (compute_uv=True, k={K_COMPONENTS}) on Dense NumPy Array ---\")\n",
    "try:\n",
    "    # Explicitly pass k, let method='auto' decide the backend\n",
    "    result = svd_computer.compute(matrix_np, k=K_COMPONENTS, compute_uv=True, method='auto')\n",
    "\n",
    "    if result is not None and isinstance(result, tuple):\n",
    "        U, S, Vh = result\n",
    "        print(f\"SVD computation successful.\")\n",
    "        if U is not None: print(f\"U shape: {U.shape}\")\n",
    "        if S is not None: print(f\"S shape: {S.shape}\")\n",
    "        if Vh is not None: print(f\"Vh shape: {Vh.shape}\")\n",
    "        print(f\"Top 5 Singular Values: {S[:5]}\")\n",
    "\n",
    "        # Optional: Check reconstruction error (meaningful for truncated/randomized)\n",
    "        if U is not None and S is not None and Vh is not None:\n",
    "             reconstructed_matrix = U @ np.diag(S) @ Vh\n",
    "             norm_diff = np.linalg.norm(matrix_np - reconstructed_matrix)\n",
    "             norm_orig = np.linalg.norm(matrix_np)\n",
    "             if norm_orig > 0:\n",
    "                print(f\"Relative reconstruction error: {norm_diff / norm_orig:.4e}\")\n",
    "             else:\n",
    "                 print(\"Original matrix norm is zero, cannot compute relative error.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Auto SVD: {e}\")"
   ],
   "id": "d01ecd2545cbd849",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 1: Auto SVD (compute_uv=True, k=20) on Dense NumPy Array ---\n",
      "SVD computation successful.\n",
      "U shape: (1000, 20)\n",
      "S shape: (20,)\n",
      "Vh shape: (20, 500)\n",
      "Top 5 Singular Values: [353.92874   15.408077  15.321458  15.289583  15.168637]\n",
      "Relative reconstruction error: 4.7357e-01\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 2: Full SVD\n",
    "\n",
    "Compute the full SVD. This can be slow and memory-intensive for large matrices, so we use the smaller dense matrix (`matrix_np_small`). We explicitly request `method='full'`. The backend will be PyTorch (if available) or NumPy."
   ],
   "id": "d8ed7f0d24cfbb00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:50:45.984784Z",
     "start_time": "2025-04-13T17:50:45.941621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Example 2: Full SVD on Smaller NumPy Array\n",
    "\n",
    "print(\"\\n--- Example 2: Full SVD (compute_uv=True) on Smaller Dense NumPy Array ---\")\n",
    "try:\n",
    "    result_full = svd_computer.compute(matrix_np_small, method='full', compute_uv=True)\n",
    "\n",
    "    if result_full is not None and isinstance(result_full, tuple):\n",
    "        U_full, S_full, Vh_full = result_full\n",
    "        print(f\"Full SVD computation successful.\")\n",
    "        if U_full is not None: print(f\"U_full shape: {U_full.shape}\")\n",
    "        if S_full is not None: print(f\"S_full shape: {S_full.shape}\")\n",
    "        if Vh_full is not None: print(f\"Vh_full shape: {Vh_full.shape}\")\n",
    "        print(f\"Top 5 Singular Values: {S_full[:5]}\")\n",
    "\n",
    "        # Optional: Check full reconstruction error (should be close to zero)\n",
    "        if U_full is not None and S_full is not None and Vh_full is not None:\n",
    "            # Need to handle shapes carefully for full SVD reconstruction\n",
    "            # U is (m, m), S is (min(m,n),), Vh is (n, n) -> use U[:, :k] @ diag(S) @ Vh[:k, :] where k=len(S)\n",
    "            k_full = S_full.size\n",
    "            reconstructed_full = U_full[:, :k_full] @ np.diag(S_full) @ Vh_full[:k_full, :]\n",
    "            norm_diff_full = np.linalg.norm(matrix_np_small - reconstructed_full)\n",
    "            norm_orig_full = np.linalg.norm(matrix_np_small)\n",
    "            if norm_orig_full > 0:\n",
    "                print(f\"Relative reconstruction error (full): {norm_diff_full / norm_orig_full:.4e}\")\n",
    "            else:\n",
    "                print(\"Original matrix norm is zero, cannot compute relative error.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Full SVD: {e}\")"
   ],
   "id": "5fb9450cd5f95439",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 2: Full SVD (compute_uv=True) on Smaller Dense NumPy Array ---\n",
      "Full SVD computation successful.\n",
      "U_full shape: (100, 100)\n",
      "S_full shape: (50,)\n",
      "Vh_full shape: (50, 50)\n",
      "Top 5 Singular Values: [35.535755   4.735351   4.539307   4.4508214  4.27382  ]\n",
      "Relative reconstruction error (full): 1.4032e+00\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 3: Explicitly Randomized SVD\n",
    "\n",
    "Force the use of `method='randomized'` (requires Scikit-learn). This computes an approximate SVD, often faster for large matrices than exact truncated methods. We also pass an extra backend-specific argument `n_iter`."
   ],
   "id": "9e0929bd9430ddae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:52:44.766277Z",
     "start_time": "2025-04-13T17:52:44.755272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Example 3: Randomized SVD (k=K_COMPONENTS) on NumPy Array\n",
    "\n",
    "print(f\"\\n--- Example 3: Randomized SVD (compute_uv=True, k={K_COMPONENTS}) on Dense NumPy Array ---\")\n",
    "if _SKLEARN_AVAILABLE:\n",
    "    try:\n",
    "        # Pass extra argument n_iter for sklearn.utils.extmath.randomized_svd\n",
    "        result_rand = svd_computer.compute(matrix_np, method='randomized', k=K_COMPONENTS, compute_uv=True, n_iter=7)\n",
    "\n",
    "        if result_rand is not None and isinstance(result_rand, tuple):\n",
    "            U_rand, S_rand, Vh_rand = result_rand\n",
    "            print(f\"Randomized SVD computation successful (n_iter=7).\")\n",
    "            if U_rand is not None: print(f\"U_rand shape: {U_rand.shape}\")\n",
    "            if S_rand is not None: print(f\"S_rand shape: {S_rand.shape}\")\n",
    "            if Vh_rand is not None: print(f\"Vh_rand shape: {Vh_rand.shape}\")\n",
    "            print(f\"Top 5 Singular Values: {S_rand[:5]}\")\n",
    "\n",
    "            # Optional: Check reconstruction error\n",
    "            if U_rand is not None and S_rand is not None and Vh_rand is not None:\n",
    "                 reconstructed_rand = U_rand @ np.diag(S_rand) @ Vh_rand\n",
    "                 norm_diff_rand = np.linalg.norm(matrix_np - reconstructed_rand)\n",
    "                 norm_orig = np.linalg.norm(matrix_np)\n",
    "                 if norm_orig > 0:\n",
    "                    print(f\"Relative reconstruction error (randomized): {norm_diff_rand / norm_orig:.4e}\")\n",
    "                 else:\n",
    "                    print(\"Original matrix norm is zero, cannot compute relative error.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Randomized SVD: {e}\")\n",
    "else:\n",
    "    print(\"Skipping Randomized SVD example: Scikit-learn not available.\")"
   ],
   "id": "5d861c7729dc1daa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 3: Randomized SVD (compute_uv=True, k=20) on Dense NumPy Array ---\n",
      "Randomized SVD computation successful (n_iter=7).\n",
      "U_rand shape: (1000, 20)\n",
      "S_rand shape: (20,)\n",
      "Vh_rand shape: (20, 500)\n",
      "Top 5 Singular Values: [353.92874   15.408077  15.321458  15.289583  15.168637]\n",
      "Relative reconstruction error (randomized): 4.7357e-01\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 4: Values Only\n",
    "\n",
    "Compute only the singular values (`S`) using `method='values_only'`. If PyTorch is available, this should use the optimized `torch.linalg.svdvals`. Otherwise, it will likely fall back to computing the full SVD and discarding `U` and `Vh`."
   ],
   "id": "91df73049bf6a9be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:53:58.951515Z",
     "start_time": "2025-04-13T17:53:58.923588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Example 4: Values Only SVD on NumPy Array\n",
    "\n",
    "print(\"\\n--- Example 4: Values Only SVD (compute_uv=False) on Dense NumPy Array ---\")\n",
    "try:\n",
    "    # Request only singular values\n",
    "    S_vals_only = svd_computer.compute(matrix_np, method='values_only', compute_uv=False)\n",
    "\n",
    "    if S_vals_only is not None:\n",
    "        print(f\"Singular Values Only computation successful.\")\n",
    "        print(f\"S_vals_only shape: {S_vals_only.shape}\")\n",
    "        print(f\"Top 5 Singular Values: {S_vals_only[:5]}\")\n",
    "        print(f\"Smallest 5 Singular Values: {S_vals_only[-5:]}\") # Should be sorted descending\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Values Only SVD: {e}\")"
   ],
   "id": "120f007ad315899a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 4: Values Only SVD (compute_uv=False) on Dense NumPy Array ---\n",
      "Singular Values Only computation successful.\n",
      "S_vals_only shape: (500,)\n",
      "Top 5 Singular Values: [353.92877    15.480578   15.406039   15.3439455  15.256517 ]\n",
      "Smallest 5 Singular Values: [2.895017  2.8555083 2.8287802 2.7462342 2.705585 ]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 5: Sparse Matrix Input\n",
    "\n",
    "Demonstrate using a SciPy sparse matrix as input. With `method='auto'` and a specified `k`, `EfficientSVD` should select an appropriate sparse SVD backend (likely `scipy.sparse.linalg.svds` or `sklearn.decomposition.TruncatedSVD`/`randomized_svd`)."
   ],
   "id": "4ae106586bb42790"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:54:47.245622Z",
     "start_time": "2025-04-13T17:54:47.233524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Example 5: Auto SVD (k=K_COMPONENTS) on Sparse Matrix\n",
    "\n",
    "print(f\"\\n--- Example 5: Auto SVD (compute_uv=True, k={K_COMPONENTS}) on Sparse Matrix ---\")\n",
    "if matrix_sparse is not None:\n",
    "    try:\n",
    "        result_sparse = svd_computer.compute(matrix_sparse, k=K_COMPONENTS, compute_uv=True, method='auto')\n",
    "\n",
    "        if result_sparse is not None and isinstance(result_sparse, tuple):\n",
    "            U_sp, S_sp, Vh_sp = result_sparse\n",
    "            print(f\"SVD computation successful for sparse input.\")\n",
    "            if U_sp is not None: print(f\"U_sp shape: {U_sp.shape}\")\n",
    "            if S_sp is not None: print(f\"S_sp shape: {S_sp.shape}\")\n",
    "            if Vh_sp is not None: print(f\"Vh_sp shape: {Vh_sp.shape}\")\n",
    "            print(f\"Top 5 Singular Values: {S_sp[:5]}\")\n",
    "\n",
    "            # Reconstruction check is more complex/costly for sparse matrices, skipping detailed error calculation.\n",
    "            print(\"Reconstruction check skipped for sparse matrix input.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during SVD on sparse matrix: {e}\")\n",
    "else:\n",
    "    print(\"Skipping Sparse Matrix SVD example: Sparse matrix was not created (SciPy might be missing).\")"
   ],
   "id": "b9af13d5b573c4f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 5: Auto SVD (compute_uv=True, k=20) on Sparse Matrix ---\n",
      "SVD computation successful for sparse input.\n",
      "U_sp shape: (1000, 20)\n",
      "S_sp shape: (20,)\n",
      "Vh_sp shape: (20, 500)\n",
      "Top 5 Singular Values: [18.386974   6.8904147  6.808587   6.783335   6.7562876]\n",
      "Reconstruction check skipped for sparse matrix input.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 6: PyTorch Tensor Input (with GPU option)\n",
    "\n",
    "Show passing a PyTorch tensor directly. If a GPU is available and the tensor is moved to the GPU (uncomment the relevant lines in the data preparation cell), `EfficientSVD` should leverage PyTorch's GPU-accelerated SVD when appropriate (e.g., for `method='full'` or `method='values_only'`, or potentially some drivers used by `auto`). The results (`U`, `S`, `Vh`) are consistently returned as NumPy arrays."
   ],
   "id": "328fe9a53c8322f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T17:55:48.070190Z",
     "start_time": "2025-04-13T17:55:47.842310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Example 6: Auto SVD (k=K_COMPONENTS) on PyTorch Tensor\n",
    "\n",
    "print(f\"\\n--- Example 6: Auto SVD (compute_uv=True, k={K_COMPONENTS}) on PyTorch Tensor ---\")\n",
    "if matrix_torch is not None:\n",
    "    # Optional: Try moving tensor to GPU right before compute if not done globally\n",
    "    if torch.cuda.is_available() and matrix_torch.device.type != 'cuda':\n",
    "         try:\n",
    "             matrix_torch_gpu = matrix_torch.cuda()\n",
    "             print(f\"Attempting computation on GPU: {matrix_torch_gpu.device}\")\n",
    "             input_tensor = matrix_torch_gpu\n",
    "         except Exception as e:\n",
    "             print(f\"Failed to move tensor to GPU for this example: {e}. Using CPU tensor.\")\n",
    "             input_tensor = matrix_torch\n",
    "    else:\n",
    "         print(f\"Using tensor on device: {matrix_torch.device}\")\n",
    "         input_tensor = matrix_torch # Use the CPU tensor prepared earlier or already on GPU\n",
    "\n",
    "    try:\n",
    "        # Using auto method, PyTorch backend likely chosen if k is large or full/values_only selected\n",
    "        result_torch = svd_computer.compute(input_tensor, k=K_COMPONENTS, compute_uv=True, method='auto')\n",
    "\n",
    "        if result_torch is not None and isinstance(result_torch, tuple):\n",
    "            U_pt, S_pt, Vh_pt = result_torch\n",
    "            print(f\"SVD computation successful for PyTorch tensor input.\")\n",
    "            # Verify outputs are NumPy arrays\n",
    "            print(f\"Output types: U({type(U_pt)}), S({type(S_pt)}), Vh({type(Vh_pt)})\")\n",
    "            if U_pt is not None: print(f\"U_pt shape: {U_pt.shape}\")\n",
    "            if S_pt is not None: print(f\"S_pt shape: {S_pt.shape}\")\n",
    "            if Vh_pt is not None: print(f\"Vh_pt shape: {Vh_pt.shape}\")\n",
    "            print(f\"Top 5 Singular Values: {S_pt[:5]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during SVD on PyTorch tensor: {e}\")\n",
    "else:\n",
    "    print(\"Skipping PyTorch Tensor SVD example: PyTorch tensor was not created.\")"
   ],
   "id": "db7f4fb01a1d551e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 6: Auto SVD (compute_uv=True, k=20) on PyTorch Tensor ---\n",
      "Attempting computation on GPU: cuda:0\n",
      "SVD computation successful for PyTorch tensor input.\n",
      "Output types: U(<class 'numpy.ndarray'>), S(<class 'numpy.ndarray'>), Vh(<class 'numpy.ndarray'>)\n",
      "U_pt shape: (1000, 20)\n",
      "S_pt shape: (20,)\n",
      "Vh_pt shape: (20, 500)\n",
      "Top 5 Singular Values: [353.92874   15.408077  15.321458  15.289583  15.168637]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the `EfficientSVD` class, showcasing its ability to compute SVD using various methods (`auto`, `full`, `truncated`, `randomized`, `values_only`) and handle different input types (NumPy, SciPy sparse, PyTorch tensors). The `auto` method intelligently selects an appropriate backend based on the input and parameters, aiming for efficiency. You can modify the parameters in the \"Prepare Example Data\" cell and rerun the examples to experiment further."
   ],
   "id": "77cf18d66be00a04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
